{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "96a6a1e1",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-03-08T16:37:17.976321Z",
     "iopub.status.busy": "2024-03-08T16:37:17.976012Z",
     "iopub.status.idle": "2024-03-08T16:37:20.109322Z",
     "shell.execute_reply": "2024-03-08T16:37:20.108455Z"
    },
    "papermill": {
     "duration": 2.143552,
     "end_time": "2024-03-08T16:37:20.111079",
     "exception": false,
     "start_time": "2024-03-08T16:37:17.967527",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pickle\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "import xgboost as XGB\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3a84163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/simon/.kaggle/kaggle.json'\n",
      "All Datasets are already available.\n"
     ]
    }
   ],
   "source": [
    "## Test cell for simon: Using Kaggle API to download the datasets indepent of github and its filesize limitations. Storing it in folder located outside of the repo.\n",
    "# If this works, all filepaths have to be adjusted in all notebooks to make use of the downloaded datasets.\n",
    "#RUN THIS CELL ONLY ONCE FOR ALL NOTEBOOKS!\n",
    "\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "#configuring and authentification with kaggle api. This could be configured so that a authentification mask is shown?\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "\n",
    "#Configuring the metadata for the ecg heartbeat data (original username etc)\n",
    "dataset_owner = \"shayanfazeli\"\n",
    "dataset_name = \"heartbeat\"\n",
    "\n",
    "#Configuring a download path that is NOT in the current github repo (so the big files are not pushed and cause an error!) --> Links to filepaths have to be dynamically adjusted\n",
    "download_path = \"../data/KAGGLE_datasets\" #In this case we use the data folder that is in the .gitignore list and therefore not pushed! To keep everything in one local repo.\n",
    "\n",
    "# Download structure: First check if dataset is already downloaded, else download it and store it in download path (should be outside git repo!)\n",
    "dataset_folder = os.path.join(download_path, dataset_name)\n",
    "if not os.path.exists(dataset_folder):\n",
    "    # Case 1: Dataset path is not created --> Create it and download datasets into it\n",
    "    api.dataset_download_files(dataset_owner + \"/\" + dataset_name, path=download_path + \"/\" + dataset_name, unzip=True)\n",
    "    print(\"Datasets are downloaded and unzipped.\")\n",
    "else:\n",
    "    # Case 2: Folder is created, but datasets might be missing\n",
    "    missing_files = [] \n",
    "    for file_name in [\"mitbih_test.csv\", \"mitbih_train.csv\", \"ptbdb_abnormal.csv\", \"ptbdb_normal.csv\"]:  # These are the hardcoded names of the datasets that should be downloaded.\n",
    "        file_path = os.path.join(dataset_folder, file_name)\n",
    "        if not os.path.exists(file_path):\n",
    "            missing_files.append(file_name)\n",
    "\n",
    "    if missing_files:\n",
    "        # If the list contains missing files, download ALL files and overwrite the old folder.\n",
    "        api.dataset_download_files(dataset_owner + \"/\" + dataset_name, path=download_path + \"/\" + dataset_name, unzip=True, force=True)\n",
    "        print(\"Missing data was donwloaded and unzipped. All Datasets are now available.\")\n",
    "    else:\n",
    "        print(\"All Datasets are already available.\")\n",
    "\n",
    "#Creating new variable that links to the datasets and can be used in the rest of the code.\n",
    "path_to_datasets = download_path + \"/\" + dataset_name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06073fe3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T16:37:20.125597Z",
     "iopub.status.busy": "2024-03-08T16:37:20.125236Z",
     "iopub.status.idle": "2024-03-08T16:37:20.128675Z",
     "shell.execute_reply": "2024-03-08T16:37:20.128113Z"
    },
    "papermill": {
     "duration": 0.01209,
     "end_time": "2024-03-08T16:37:20.130036",
     "exception": false,
     "start_time": "2024-03-08T16:37:20.117946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71a126b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T16:37:20.144307Z",
     "iopub.status.busy": "2024-03-08T16:37:20.143891Z",
     "iopub.status.idle": "2024-03-08T16:37:28.554329Z",
     "shell.execute_reply": "2024-03-08T16:37:28.553540Z"
    },
    "papermill": {
     "duration": 8.419779,
     "end_time": "2024-03-08T16:37:28.556365",
     "exception": false,
     "start_time": "2024-03-08T16:37:20.136586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This cell now makes use of the downloadfolder for the datasets. If already available locally, the filepaths can be changed.\n",
    "df_train= pd.read_csv(path_to_datasets + \"/\" + 'mitbih_train.csv', header=None)\n",
    "df_test=pd.read_csv(path_to_datasets + \"/\" +  'mitbih_test.csv',header=None)\n",
    "\n",
    "#split target and value\n",
    "train_target=df_train[187]\n",
    "test_target=df_test[187]\n",
    "train=df_train.drop(187,axis=1)\n",
    "test=df_test.drop(187,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f3cbb4eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T16:37:28.570682Z",
     "iopub.status.busy": "2024-03-08T16:37:28.570419Z",
     "iopub.status.idle": "2024-03-08T16:37:28.573932Z",
     "shell.execute_reply": "2024-03-08T16:37:28.573208Z"
    },
    "papermill": {
     "duration": 0.012332,
     "end_time": "2024-03-08T16:37:28.575526",
     "exception": false,
     "start_time": "2024-03-08T16:37:28.563194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    oversample = False\n",
    "    undersample = False\n",
    "    sample_name = \"UNDEFINED_SAMPLE\"\n",
    "\n",
    "Train_SVM =  False #trains the SVM Model without Gridsearch\n",
    "Train_KNN = True #trains the KNN Model without Gridsearch\n",
    "Train_DTC = True #trains the DTC Model without Gridsearch\n",
    "Train_RF = True #trains the RF Model without Gridsearch\n",
    "Train_XGB = True #trains the XGB Model without Gridsearch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "045ff622",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T16:37:28.590061Z",
     "iopub.status.busy": "2024-03-08T16:37:28.589796Z",
     "iopub.status.idle": "2024-03-08T16:37:28.593402Z",
     "shell.execute_reply": "2024-03-08T16:37:28.592581Z"
    },
    "papermill": {
     "duration": 0.012892,
     "end_time": "2024-03-08T16:37:28.595250",
     "exception": false,
     "start_time": "2024-03-08T16:37:28.582358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "oversampler = SMOTE()\n",
    "undersampler = RandomUnderSampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "303ceae0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T16:37:28.609288Z",
     "iopub.status.busy": "2024-03-08T16:37:28.609005Z",
     "iopub.status.idle": "2024-03-08T16:37:29.972590Z",
     "shell.execute_reply": "2024-03-08T16:37:29.971888Z"
    },
    "papermill": {
     "duration": 1.372662,
     "end_time": "2024-03-08T16:37:29.974472",
     "exception": false,
     "start_time": "2024-03-08T16:37:28.601810",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the original mitbih dataset\n",
      "Sample Name: MITBIH_A_Original\n"
     ]
    }
   ],
   "source": [
    "if Config.oversample:\n",
    "    train, train_target = oversampler.fit_resample(df_train.iloc[:,:-1], df_train.iloc[:,-1])\n",
    "    Config.sample_name = \"MITBIH_B_SMOTE\"\n",
    "    print(\"Sample Name:\", Config.sample_name)\n",
    "elif Config.undersample:\n",
    "    train, train_target = undersampler.fit_resample(df_train.iloc[:,:-1], df_train.iloc[:,-1])\n",
    "    Config.sample_name = \"MITBIH_C_RUS\"\n",
    "    print(\"Sample Name:\", Config.sample_name)\n",
    "else: \n",
    "    print(\"Using the original mitbih dataset\")\n",
    "    Config.sample_name = \"MITBIH_A_Original\"\n",
    "    print(\"Sample Name:\", Config.sample_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "12e9d176",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to save models and classification report directly after running.\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "def save_model_and_report(model, report, model_filename, report_filename, model_folder=\"../models/ML_Models\", report_folder=\"../reports/figures/ML_Models\"):\n",
    "    # Save the model\n",
    "    model_savepath = os.path.join(model_folder, model_filename)\n",
    "    with open(model_savepath, \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "    print(f\"The model was saved as {model_filename} in folder {model_folder}.\")\n",
    "\n",
    "    # Save the classification report\n",
    "    report_savepath = os.path.join(report_folder, report_filename)\n",
    "    with open(report_savepath, \"w\") as f:\n",
    "        f.write(report)\n",
    "    print(f\"The classification report was saved as {report_filename} in folder {report_folder}.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "da81ef52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T16:37:29.989075Z",
     "iopub.status.busy": "2024-03-08T16:37:29.988820Z",
     "iopub.status.idle": "2024-03-08T16:37:29.994384Z",
     "shell.execute_reply": "2024-03-08T16:37:29.993649Z"
    },
    "papermill": {
     "duration": 0.014706,
     "end_time": "2024-03-08T16:37:29.996128",
     "exception": false,
     "start_time": "2024-03-08T16:37:29.981422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(362355, 187)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b9fe67",
   "metadata": {
    "papermill": {
     "duration": 0.006442,
     "end_time": "2024-03-08T16:37:30.009438",
     "exception": false,
     "start_time": "2024-03-08T16:37:30.002996",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **SVM**\n",
    "\n",
    "<font color='red'>PUT SOME NOTES / EXPLANATORY WORDS AS TEAM HERE IF NEEDED</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "140181b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T16:37:30.024672Z",
     "iopub.status.busy": "2024-03-08T16:37:30.024196Z",
     "iopub.status.idle": "2024-03-08T16:37:30.027938Z",
     "shell.execute_reply": "2024-03-08T16:37:30.027182Z"
    },
    "papermill": {
     "duration": 0.013468,
     "end_time": "2024-03-08T16:37:30.029503",
     "exception": false,
     "start_time": "2024-03-08T16:37:30.016035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9911    0.9373    0.9634     18118\n",
      "         1.0     0.4194    0.8237    0.5558       556\n",
      "         2.0     0.8917    0.9323    0.9115      1448\n",
      "         3.0     0.2822    0.9198    0.4319       162\n",
      "         4.0     0.9686    0.9776    0.9731      1608\n",
      "\n",
      "    accuracy                         0.9369     21892\n",
      "   macro avg     0.7106    0.9181    0.7672     21892\n",
      "weighted avg     0.9631    0.9369    0.9464     21892\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Just the code for model creation, fitting and creating the report out of the predictions.\n",
    "if Train_SVM == True:\n",
    "    model = SVC(cache_size=500)\n",
    "    model.fit(train,train_target)\n",
    "    predictions = model.predict(test)\n",
    "    report=classification_report(test_target, predictions, digits=4)\n",
    "    print(report)\n",
    "    #Calling the save_model_and_report function for the SVM Model\n",
    "    model_filename = f\"SVM_Basemodel_no_gridsearch_{Config.sample_name}.pkl\"\n",
    "    report_filename = f\"SVM_Basemodel_no_gridsearch_{Config.sample_name}_classification_report.txt\"\n",
    "    save_model_and_report(model, report, model_filename, report_filename)\n",
    "else:\n",
    "    print(\"SVM Model withoud gridsearch is not trained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66785f33",
   "metadata": {
    "papermill": {
     "duration": 0.006836,
     "end_time": "2024-03-08T17:18:35.863195",
     "exception": false,
     "start_time": "2024-03-08T17:18:35.856359",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **KNN**\n",
    "\n",
    "<font color='red'>PUT SOME NOTES / EXPLANATORY WORDS AS TEAM HERE IF NEEDED</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3784bfce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T17:18:35.878594Z",
     "iopub.status.busy": "2024-03-08T17:18:35.878298Z",
     "iopub.status.idle": "2024-03-08T17:18:35.881911Z",
     "shell.execute_reply": "2024-03-08T17:18:35.881200Z"
    },
    "papermill": {
     "duration": 0.013146,
     "end_time": "2024-03-08T17:18:35.883733",
     "exception": false,
     "start_time": "2024-03-08T17:18:35.870587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if Train_KNN == True:\n",
    "    model = KNN(n_jobs = -1)\n",
    "    model.fit(train,train_target)\n",
    "    predictions = model.predict(test)\n",
    "    report=classification_report(test_target, predictions, digits=4)\n",
    "    print(report)\n",
    "    #Calling the save_model_and_report function for the KNN Model\n",
    "    model_filename = f\"KNN_Basemodel_no_gridsearch_{Config.sample_name}.pkl\"\n",
    "    report_filename = f\"KNN_Basemodel_no_gridsearch_{Config.sample_name}_classification_report.txt\"\n",
    "    save_model_and_report(model, report, model_filename, report_filename)\n",
    "else:\n",
    "    print(\"KNN Model without gridsearch is not trained.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278d4c36",
   "metadata": {
    "papermill": {
     "duration": 0.006902,
     "end_time": "2024-03-08T17:30:16.867283",
     "exception": false,
     "start_time": "2024-03-08T17:30:16.860381",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Decision Tree**\n",
    "\n",
    "<font color='red'>PUT SOME NOTES / EXPLANATORY WORDS AS TEAM HERE IF NEEDED</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9ba3453f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T17:30:16.883819Z",
     "iopub.status.busy": "2024-03-08T17:30:16.883518Z",
     "iopub.status.idle": "2024-03-08T17:30:16.886952Z",
     "shell.execute_reply": "2024-03-08T17:30:16.886210Z"
    },
    "papermill": {
     "duration": 0.01312,
     "end_time": "2024-03-08T17:30:16.888499",
     "exception": false,
     "start_time": "2024-03-08T17:30:16.875379",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if Train_DTC == True:\n",
    "    model = DTC()\n",
    "    model.fit(train,train_target)\n",
    "    predictions = model.predict(test)\n",
    "    report=classification_report(test_target, predictions, digits=4)\n",
    "    print(report)\n",
    "    #Calling the save_model_and_report function for the Decision Tree Model\n",
    "    model_filename = f\"DTC_Basemodel_no_gridsearch_{Config.sample_name}.pkl\"\n",
    "    report_filename = f\"DTC_Basemodel_no_gridsearch_{Config.sample_name}_classification_report.txt\"\n",
    "    save_model_and_report(model, report, model_filename, report_filename)\n",
    "else:\n",
    "    print(\"Decision Tree Model without gridsearch is not trained.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a899a01",
   "metadata": {
    "papermill": {
     "duration": 0.007861,
     "end_time": "2024-03-08T17:34:11.478217",
     "exception": false,
     "start_time": "2024-03-08T17:34:11.470356",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Random Forest**\n",
    "\n",
    "<font color='red'>PUT SOME NOTES / EXPLANATORY WORDS AS TEAM HERE IF NEEDED</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37e1a610",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T17:34:11.495348Z",
     "iopub.status.busy": "2024-03-08T17:34:11.494517Z",
     "iopub.status.idle": "2024-03-08T17:34:11.498346Z",
     "shell.execute_reply": "2024-03-08T17:34:11.497634Z"
    },
    "papermill": {
     "duration": 0.014147,
     "end_time": "2024-03-08T17:34:11.500026",
     "exception": false,
     "start_time": "2024-03-08T17:34:11.485879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if Train_RF == True:\n",
    "    model = RFC(n_jobs = -1)\n",
    "    model.fit(train,train_target)\n",
    "    predictions = model.predict(test)\n",
    "    report=classification_report(test_target, predictions, digits=4)\n",
    "    print(report)\n",
    "    #Calling the save_model_and_report function for the Random Forest Model\n",
    "    model_filename = f\"RFC_Basemodel_no_gridsearch_{Config.sample_name}.pkl\"\n",
    "    report_filename = f\"RFC_Basemodel_no_gridsearch_{Config.sample_name}_classification_report.txt\"\n",
    "    save_model_and_report(model, report, model_filename, report_filename)\n",
    "else:\n",
    "    print(\"Random Forest Model without gridsearch is not trained.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199ef92a",
   "metadata": {
    "papermill": {
     "duration": 0.007353,
     "end_time": "2024-03-08T17:37:53.962258",
     "exception": false,
     "start_time": "2024-03-08T17:37:53.954905",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **XGBoost**\n",
    "\n",
    "<font color='red'>PUT SOME NOTES / EXPLANATORY WORDS AS TEAM HERE IF NEEDED</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a866d4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T17:37:53.978948Z",
     "iopub.status.busy": "2024-03-08T17:37:53.978443Z",
     "iopub.status.idle": "2024-03-08T17:37:53.981708Z",
     "shell.execute_reply": "2024-03-08T17:37:53.981176Z"
    },
    "papermill": {
     "duration": 0.013253,
     "end_time": "2024-03-08T17:37:53.983124",
     "exception": false,
     "start_time": "2024-03-08T17:37:53.969871",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if Train_XGB == True:\n",
    "    model = XGB.XGBClassifier(objective='binary:logistic')\n",
    "    model.fit(train,train_target)\n",
    "    predictions = model.predict(test)\n",
    "    report=classification_report(test_target, predictions, digits=4)\n",
    "    print(report)\n",
    "    #Calling the save_model_and_report function for the XGB Model\n",
    "    model_filename = f\"XGB_Basemodel_no_gridsearch_{Config.sample_name}.pkl\"\n",
    "    report_filename = f\"XGB_Basemodel_no_gridsearch_{Config.sample_name}_classification_report.txt\"\n",
    "    save_model_and_report(model, report, model_filename, report_filename)\n",
    "else:\n",
    "    print(\"XBG Model without gridsearch is not trained.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 29414,
     "sourceId": 37484,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30626,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3755.277893,
   "end_time": "2024-03-08T17:39:50.297430",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-08T16:37:15.019537",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
