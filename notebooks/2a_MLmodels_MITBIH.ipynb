{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "96a6a1e1",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-03-08T16:37:17.976321Z",
     "iopub.status.busy": "2024-03-08T16:37:17.976012Z",
     "iopub.status.idle": "2024-03-08T16:37:20.109322Z",
     "shell.execute_reply": "2024-03-08T16:37:20.108455Z"
    },
    "papermill": {
     "duration": 2.143552,
     "end_time": "2024-03-08T16:37:20.111079",
     "exception": false,
     "start_time": "2024-03-08T16:37:17.967527",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pickle\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "import xgboost as XGB\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c3a84163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/simon/.kaggle/kaggle.json'\n",
      "All Datasets are already available.\n"
     ]
    }
   ],
   "source": [
    "## Test cell for simon: Using Kaggle API to download the datasets indepent of github and its filesize limitations. Storing it in folder located outside of the repo.\n",
    "# If this works, all filepaths have to be adjusted in all notebooks to make use of the downloaded datasets.\n",
    "#RUN THIS CELL ONLY ONCE FOR ALL NOTEBOOKS!\n",
    "\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "#configuring and authentification with kaggle api. This could be configured so that a authentification mask is shown?\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "\n",
    "#Configuring the metadata for the ecg heartbeat data (original username etc)\n",
    "dataset_owner = \"shayanfazeli\"\n",
    "dataset_name = \"heartbeat\"\n",
    "\n",
    "#Configuring a download path that is NOT in the current github repo (so the big files are not pushed and cause an error!) --> Links to filepaths have to be dynamically adjusted\n",
    "download_path = \"../data/KAGGLE_datasets\" #In this case we use the data folder that is in the .gitignore list and therefore not pushed! To keep everything in one local repo.\n",
    "\n",
    "# Download structure: First check if dataset is already downloaded, else download it and store it in download path (should be outside git repo!)\n",
    "dataset_folder = os.path.join(download_path, dataset_name)\n",
    "if not os.path.exists(dataset_folder):\n",
    "    # Case 1: Dataset path is not created --> Create it and download datasets into it\n",
    "    api.dataset_download_files(dataset_owner + \"/\" + dataset_name, path=download_path + \"/\" + dataset_name, unzip=True)\n",
    "    print(\"Datasets are downloaded and unzipped.\")\n",
    "else:\n",
    "    # Case 2: Folder is created, but datasets might be missing\n",
    "    missing_files = [] \n",
    "    for file_name in [\"mitbih_test.csv\", \"mitbih_train.csv\", \"ptbdb_abnormal.csv\", \"ptbdb_normal.csv\"]:  # These are the hardcoded names of the datasets that should be downloaded.\n",
    "        file_path = os.path.join(dataset_folder, file_name)\n",
    "        if not os.path.exists(file_path):\n",
    "            missing_files.append(file_name)\n",
    "\n",
    "    if missing_files:\n",
    "        # If the list contains missing files, download ALL files and overwrite the old folder.\n",
    "        api.dataset_download_files(dataset_owner + \"/\" + dataset_name, path=download_path + \"/\" + dataset_name, unzip=True, force=True)\n",
    "        print(\"Missing data was donwloaded and unzipped. All Datasets are now available.\")\n",
    "    else:\n",
    "        print(\"All Datasets are already available.\")\n",
    "\n",
    "#Creating new variable that links to the datasets and can be used in the rest of the code.\n",
    "path_to_datasets = download_path + \"/\" + dataset_name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "06073fe3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T16:37:20.125597Z",
     "iopub.status.busy": "2024-03-08T16:37:20.125236Z",
     "iopub.status.idle": "2024-03-08T16:37:20.128675Z",
     "shell.execute_reply": "2024-03-08T16:37:20.128113Z"
    },
    "papermill": {
     "duration": 0.01209,
     "end_time": "2024-03-08T16:37:20.130036",
     "exception": false,
     "start_time": "2024-03-08T16:37:20.117946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "71a126b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T16:37:20.144307Z",
     "iopub.status.busy": "2024-03-08T16:37:20.143891Z",
     "iopub.status.idle": "2024-03-08T16:37:28.554329Z",
     "shell.execute_reply": "2024-03-08T16:37:28.553540Z"
    },
    "papermill": {
     "duration": 8.419779,
     "end_time": "2024-03-08T16:37:28.556365",
     "exception": false,
     "start_time": "2024-03-08T16:37:20.136586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This cell now makes use of the downloadfolder for the datasets. If already available locally, the filepaths can be changed.\n",
    "df_train= pd.read_csv(path_to_datasets + \"/\" + 'mitbih_train.csv', header=None)\n",
    "df_test=pd.read_csv(path_to_datasets + \"/\" +  'mitbih_test.csv',header=None)\n",
    "\n",
    "#split target and value\n",
    "train_target=df_train[187]\n",
    "test_target=df_test[187]\n",
    "train=df_train.drop(187,axis=1)\n",
    "test=df_test.drop(187,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f3cbb4eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T16:37:28.570682Z",
     "iopub.status.busy": "2024-03-08T16:37:28.570419Z",
     "iopub.status.idle": "2024-03-08T16:37:28.573932Z",
     "shell.execute_reply": "2024-03-08T16:37:28.573208Z"
    },
    "papermill": {
     "duration": 0.012332,
     "end_time": "2024-03-08T16:37:28.575526",
     "exception": false,
     "start_time": "2024-03-08T16:37:28.563194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    oversample = False #refers to mitbih B_SMOTE\n",
    "    undersample = False #Refers to undersampling with random undersampler\n",
    "    sample_name = \"UNDEFINED_SAMPLE\"\n",
    "\n",
    "Train_SVM =  False #trains the SVM Model without Gridsearch\n",
    "Train_KNN = True #trains the KNN Model without Gridsearch\n",
    "Train_DTC = True #trains the DTC Model without Gridsearch\n",
    "Train_RF = True #trains the RF Model without Gridsearch\n",
    "Train_XGB = True #trains the XGB Model without Gridsearch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "045ff622",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T16:37:28.590061Z",
     "iopub.status.busy": "2024-03-08T16:37:28.589796Z",
     "iopub.status.idle": "2024-03-08T16:37:28.593402Z",
     "shell.execute_reply": "2024-03-08T16:37:28.592581Z"
    },
    "papermill": {
     "duration": 0.012892,
     "end_time": "2024-03-08T16:37:28.595250",
     "exception": false,
     "start_time": "2024-03-08T16:37:28.582358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "oversampler = SMOTE()\n",
    "undersampler = RandomUnderSampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "303ceae0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T16:37:28.609288Z",
     "iopub.status.busy": "2024-03-08T16:37:28.609005Z",
     "iopub.status.idle": "2024-03-08T16:37:29.972590Z",
     "shell.execute_reply": "2024-03-08T16:37:29.971888Z"
    },
    "papermill": {
     "duration": 1.372662,
     "end_time": "2024-03-08T16:37:29.974472",
     "exception": false,
     "start_time": "2024-03-08T16:37:28.601810",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the original mitbih dataset\n",
      "Sample Name: MITBIH_A_Original\n"
     ]
    }
   ],
   "source": [
    "if Config.oversample:\n",
    "    train, train_target = oversampler.fit_resample(df_train.iloc[:,:-1], df_train.iloc[:,-1])\n",
    "    Config.sample_name = \"MITBIH_B_SMOTE\"\n",
    "    print(\"Sample Name:\", Config.sample_name)\n",
    "elif Config.undersample:\n",
    "    train, train_target = undersampler.fit_resample(df_train.iloc[:,:-1], df_train.iloc[:,-1])\n",
    "    Config.sample_name = \"MITBIH_C_RUS\"\n",
    "    print(\"Sample Name:\", Config.sample_name)\n",
    "else: \n",
    "    print(\"Using the original mitbih dataset\")\n",
    "    Config.sample_name = \"MITBIH_A_Original\"\n",
    "    print(\"Sample Name:\", Config.sample_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "12e9d176",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to save models and classification report directly after running.\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "def save_model_and_report(model, report, model_filename, report_filename, model_folder=\"../models/ML_Models\", report_folder=\"../reports/figures/ML_Models\"):\n",
    "    # Save the model\n",
    "    model_savepath = os.path.join(model_folder, model_filename)\n",
    "    with open(model_savepath, \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "    print(f\"The model was saved as {model_filename} in folder {model_folder}.\")\n",
    "\n",
    "    # Save the classification report\n",
    "    report_savepath = os.path.join(report_folder, report_filename)\n",
    "    with open(report_savepath, \"w\") as f:\n",
    "        f.write(report)\n",
    "    print(f\"The classification report was saved as {report_filename} in folder {report_folder}.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "da81ef52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T16:37:29.989075Z",
     "iopub.status.busy": "2024-03-08T16:37:29.988820Z",
     "iopub.status.idle": "2024-03-08T16:37:29.994384Z",
     "shell.execute_reply": "2024-03-08T16:37:29.993649Z"
    },
    "papermill": {
     "duration": 0.014706,
     "end_time": "2024-03-08T16:37:29.996128",
     "exception": false,
     "start_time": "2024-03-08T16:37:29.981422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87554, 187)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b9fe67",
   "metadata": {
    "papermill": {
     "duration": 0.006442,
     "end_time": "2024-03-08T16:37:30.009438",
     "exception": false,
     "start_time": "2024-03-08T16:37:30.002996",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **SVM**\n",
    "\n",
    "<font color='red'>PUT SOME NOTES / EXPLANATORY WORDS AS TEAM HERE IF NEEDED</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "140181b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T16:37:30.024672Z",
     "iopub.status.busy": "2024-03-08T16:37:30.024196Z",
     "iopub.status.idle": "2024-03-08T16:37:30.027938Z",
     "shell.execute_reply": "2024-03-08T16:37:30.027182Z"
    },
    "papermill": {
     "duration": 0.013468,
     "end_time": "2024-03-08T16:37:30.029503",
     "exception": false,
     "start_time": "2024-03-08T16:37:30.016035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Model withoud gridsearch is not trained\n"
     ]
    }
   ],
   "source": [
    "#Just the code for model creation, fitting and creating the report out of the predictions.\n",
    "if Train_SVM == True:\n",
    "    model = SVC(cache_size=500)\n",
    "    model.fit(train,train_target)\n",
    "    predictions = model.predict(test)\n",
    "    report=classification_report(test_target, predictions, digits=4)\n",
    "    print(report)\n",
    "    #Calling the save_model_and_report function for the SVM Model\n",
    "    model_filename = f\"SVM_Basemodel_no_gridsearch_{Config.sample_name}.pkl\"\n",
    "    report_filename = f\"SVM_Basemodel_no_gridsearch_{Config.sample_name}_classification_report.txt\"\n",
    "    save_model_and_report(model, report, model_filename, report_filename)\n",
    "else:\n",
    "    print(\"SVM Model withoud gridsearch is not trained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66785f33",
   "metadata": {
    "papermill": {
     "duration": 0.006836,
     "end_time": "2024-03-08T17:18:35.863195",
     "exception": false,
     "start_time": "2024-03-08T17:18:35.856359",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **KNN**\n",
    "\n",
    "<font color='red'>PUT SOME NOTES / EXPLANATORY WORDS AS TEAM HERE IF NEEDED</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3784bfce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T17:18:35.878594Z",
     "iopub.status.busy": "2024-03-08T17:18:35.878298Z",
     "iopub.status.idle": "2024-03-08T17:18:35.881911Z",
     "shell.execute_reply": "2024-03-08T17:18:35.881200Z"
    },
    "papermill": {
     "duration": 0.013146,
     "end_time": "2024-03-08T17:18:35.883733",
     "exception": false,
     "start_time": "2024-03-08T17:18:35.870587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9777    0.9946    0.9861     18118\n",
      "         1.0     0.8970    0.6421    0.7484       556\n",
      "         2.0     0.9395    0.9012    0.9200      1448\n",
      "         3.0     0.7630    0.6358    0.6936       162\n",
      "         4.0     0.9941    0.9509    0.9720      1608\n",
      "\n",
      "    accuracy                         0.9736     21892\n",
      "   macro avg     0.9143    0.8249    0.8640     21892\n",
      "weighted avg     0.9727    0.9736    0.9725     21892\n",
      "\n",
      "The model was saved as KNN_Basemodel_no_gridsearch_MITBIH_A_Original.pkl in folder ../models/ML_Models.\n",
      "The classification report was saved as KNN_Basemodel_no_gridsearch_MITBIH_A_Original_classification_report.txt in folder ../reports/figures/ML_Models.\n"
     ]
    }
   ],
   "source": [
    "if Train_KNN == True:\n",
    "    model = KNN(n_jobs = -1)\n",
    "    model.fit(train,train_target)\n",
    "    predictions = model.predict(test)\n",
    "    report=classification_report(test_target, predictions, digits=4)\n",
    "    print(report)\n",
    "    #Calling the save_model_and_report function for the KNN Model\n",
    "    model_filename = f\"KNN_Basemodel_no_gridsearch_{Config.sample_name}.pkl\"\n",
    "    report_filename = f\"KNN_Basemodel_no_gridsearch_{Config.sample_name}_classification_report.txt\"\n",
    "    save_model_and_report(model, report, model_filename, report_filename)\n",
    "else:\n",
    "    print(\"KNN Model without gridsearch is not trained.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278d4c36",
   "metadata": {
    "papermill": {
     "duration": 0.006902,
     "end_time": "2024-03-08T17:30:16.867283",
     "exception": false,
     "start_time": "2024-03-08T17:30:16.860381",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Decision Tree**\n",
    "\n",
    "<font color='red'>PUT SOME NOTES / EXPLANATORY WORDS AS TEAM HERE IF NEEDED</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9ba3453f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T17:30:16.883819Z",
     "iopub.status.busy": "2024-03-08T17:30:16.883518Z",
     "iopub.status.idle": "2024-03-08T17:30:16.886952Z",
     "shell.execute_reply": "2024-03-08T17:30:16.886210Z"
    },
    "papermill": {
     "duration": 0.01312,
     "end_time": "2024-03-08T17:30:16.888499",
     "exception": false,
     "start_time": "2024-03-08T17:30:16.875379",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9758    0.9747    0.9752     18118\n",
      "         1.0     0.6398    0.6421    0.6409       556\n",
      "         2.0     0.8499    0.8640    0.8568      1448\n",
      "         3.0     0.5963    0.5926    0.5944       162\n",
      "         4.0     0.9420    0.9397    0.9408      1608\n",
      "\n",
      "    accuracy                         0.9535     21892\n",
      "   macro avg     0.8007    0.8026    0.8017     21892\n",
      "weighted avg     0.9536    0.9535    0.9536     21892\n",
      "\n",
      "The model was saved as DTC_Basemodel_no_gridsearch_UNDEFINED_SAMPLE.pkl in folder ../models/ML_Models.\n",
      "The classification report was saved as DTC_Basemodel_no_gridsearch_UNDEFINED_SAMPLE_classification_report.txt in folder ../reports/figures/ML_Models.\n"
     ]
    }
   ],
   "source": [
    "if Train_DTC == True:\n",
    "    model = DTC()\n",
    "    model.fit(train,train_target)\n",
    "    predictions = model.predict(test)\n",
    "    report=classification_report(test_target, predictions, digits=4)\n",
    "    print(report)\n",
    "    #Calling the save_model_and_report function for the Decision Tree Model\n",
    "    model_filename = f\"DTC_Basemodel_no_gridsearch_{Config.sample_name}.pkl\"\n",
    "    report_filename = f\"DTC_Basemodel_no_gridsearch_{Config.sample_name}_classification_report.txt\"\n",
    "    save_model_and_report(model, report, model_filename, report_filename)\n",
    "else:\n",
    "    print(\"Decision Tree Model without gridsearch is not trained.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a899a01",
   "metadata": {
    "papermill": {
     "duration": 0.007861,
     "end_time": "2024-03-08T17:34:11.478217",
     "exception": false,
     "start_time": "2024-03-08T17:34:11.470356",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Random Forest**\n",
    "\n",
    "<font color='red'>PUT SOME NOTES / EXPLANATORY WORDS AS TEAM HERE IF NEEDED</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "37e1a610",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T17:34:11.495348Z",
     "iopub.status.busy": "2024-03-08T17:34:11.494517Z",
     "iopub.status.idle": "2024-03-08T17:34:11.498346Z",
     "shell.execute_reply": "2024-03-08T17:34:11.497634Z"
    },
    "papermill": {
     "duration": 0.014147,
     "end_time": "2024-03-08T17:34:11.500026",
     "exception": false,
     "start_time": "2024-03-08T17:34:11.485879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Train_RF \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m      2\u001b[0m     model \u001b[38;5;241m=\u001b[39m RFC(n_jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_target\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(test)\n\u001b[1;32m      5\u001b[0m     report\u001b[38;5;241m=\u001b[39mclassification_report(test_target, predictions, digits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:489\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    478\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    481\u001b[0m ]\n\u001b[1;32m    483\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 489\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/joblib/parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1707\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if Train_RF == True:\n",
    "    model = RFC(n_jobs = -1)\n",
    "    model.fit(train,train_target)\n",
    "    predictions = model.predict(test)\n",
    "    report=classification_report(test_target, predictions, digits=4)\n",
    "    print(report)\n",
    "    #Calling the save_model_and_report function for the Random Forest Model\n",
    "    model_filename = f\"RFC_Basemodel_no_gridsearch_{Config.sample_name}.pkl\"\n",
    "    report_filename = f\"RFC_Basemodel_no_gridsearch_{Config.sample_name}_classification_report.txt\"\n",
    "    save_model_and_report(model, report, model_filename, report_filename)\n",
    "else:\n",
    "    print(\"Random Forest Model without gridsearch is not trained.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199ef92a",
   "metadata": {
    "papermill": {
     "duration": 0.007353,
     "end_time": "2024-03-08T17:37:53.962258",
     "exception": false,
     "start_time": "2024-03-08T17:37:53.954905",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **XGBoost**\n",
    "\n",
    "<font color='red'>PUT SOME NOTES / EXPLANATORY WORDS AS TEAM HERE IF NEEDED</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a866d4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T17:37:53.978948Z",
     "iopub.status.busy": "2024-03-08T17:37:53.978443Z",
     "iopub.status.idle": "2024-03-08T17:37:53.981708Z",
     "shell.execute_reply": "2024-03-08T17:37:53.981176Z"
    },
    "papermill": {
     "duration": 0.013253,
     "end_time": "2024-03-08T17:37:53.983124",
     "exception": false,
     "start_time": "2024-03-08T17:37:53.969871",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if Train_XGB == True:\n",
    "    model = XGB.XGBClassifier(objective='binary:logistic')\n",
    "    model.fit(train,train_target)\n",
    "    predictions = model.predict(test)\n",
    "    report=classification_report(test_target, predictions, digits=4)\n",
    "    print(report)\n",
    "    #Calling the save_model_and_report function for the XGB Model\n",
    "    model_filename = f\"XGB_Basemodel_no_gridsearch_{Config.sample_name}.pkl\"\n",
    "    report_filename = f\"XGB_Basemodel_no_gridsearch_{Config.sample_name}_classification_report.txt\"\n",
    "    save_model_and_report(model, report, model_filename, report_filename)\n",
    "else:\n",
    "    print(\"XBG Model without gridsearch is not trained.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 29414,
     "sourceId": 37484,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30626,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3755.277893,
   "end_time": "2024-03-08T17:39:50.297430",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-08T16:37:15.019537",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
